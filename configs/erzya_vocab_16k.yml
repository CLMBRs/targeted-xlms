# Sentencepiece vocabulary parameters
tokenizer_model: unigram
vocab_size: 16384
train_dataset_path: data/uralic/erzya/myv_combined_cleaned_train.txt
output_path: tokenizers/erzya_spm_16k
