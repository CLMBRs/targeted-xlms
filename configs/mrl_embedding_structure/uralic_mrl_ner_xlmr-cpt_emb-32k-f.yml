# task setup
task: ner
zero_shot_transfer: False
transfer_source: None
langs: ['myv', 'et', 'fi', 'hu', 'ru']
dataset_path: data/ner-uralic
# whether to start with a randomly-initialized model
random_weights: False

# model options
model_class: xlmr
model_name: models/uralic_mrl/cpt_emb-32k-focus/best-checkpoint
tokenizer_path: tokenizers/uralic_mrl_spm_32k.model
checkpoint_path: models/uralic_mrl/ner/xlmr_cpt_emb-32k-focus

# training options
random_seed: 1
epochs: 32
batch_size: 72
gradient_accumulation: 1
max_seq_length: 256
max_train_examples: 32768
# checkpoints every two epochs, so patience epochs is this parameter x2
patience: 2
