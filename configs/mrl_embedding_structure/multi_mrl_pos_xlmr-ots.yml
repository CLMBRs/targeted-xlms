# task setup
task: pos
zero_shot_transfer: False
transfer_source: None
langs: ['hy', 'eu', 'myv', 'et', 'he', 'ru', 'sme', 'te']
dataset_path: data/ud-mono
# whether to start with a randomly-initialized model
random_weights: False

# model options
model_class: xlmr
model_name: xlm-roberta-base
checkpoint_path: models/multi_mrl/pos/xlmr_ots

# training options
random_seed: 1
epochs: 64
batch_size: 36
gradient_accumulation: 2
max_seq_length: 256
max_train_examples: 32768
# checkpoints every two epochs, so patience epochs is this parameter x2
patience: 4
